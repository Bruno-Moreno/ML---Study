\section{Statistics}

\subsection{Hyphotesis Testing}

Sea $X_1, \dots X_n$ una muestra aleatoria de una distribución con densidad $f(x|\theta)$ con el parámetro $\theta \in \Omega$ (espacio de parámetros). Consideremos $\Omega_0$ y $\Omega_1$ disjuntos tales que $\Omega_0 \cup \Omega_1 = \Omega$. Un test de hipótesis se configura de la siguiente forma 

\begin{equation*}
\begin{aligned}
    H_0: \theta \in \Omega_0 \\ 
    H_A: \theta \in \Omega_1
\end{aligned}
\end{equation*}

Donde $H_0$ es la hipótesis nula y $H_A$ la hipótesis alternativa. El objetivo de un test de hipótesis es determinar si bajo $H_0$ es estadísticamente posible muestrear $X_1 , \dots, X_n$, o bien, se debiera considerar $H_1$.

\subsubsection{Mean of Normal Distribution - Known Variance}

Consideremos $X_1 , \dots X_n \sim \mathcal{N}(\mu, \sigma^2)$ con $\sigma^2$ un parámetro conocido. El test que planteamos es 
\begin{equation*}
\begin{aligned}
    H_0: \mu = \mu_0 \\ 
    H_A: \mu \neq \mu_0
\end{aligned}
\end{equation*}

Bajo la hipótesis $H_0$, suponemos que $X_1, \dots X_n \sim \mathcal{N}(\mu_0, \sigma^2)$. Por teorema del límite central, recordemos que 

$$ 
Z_n = \frac{\overline{X} - \mu_0}{\sigma / \sqrt{n}} \sim \mathcal{N}(0,1)
$$

Definimos el \textbf{p-valor} según
$$
\text{p}_{\text{value}} = P(|Z_n| \geq |z| \hspace{0.1cm} |\hspace{0.1cm} H_0) 
$$

Con $z$ el valor empírico obtenido de una muestra. Rechazamos la hipótesis nula cuando el p-valor es menor o igual que un nivel de significancia $\alpha$ (usualmente 1\%, 5\%, 10\%).

\begin{figure}[H]
    \center
    \includegraphics[scale=0.55]{notebooks/STATS/img/two_sided_test.png}
    \caption{One and Two Sided Test Diagram}
\end{figure}


Cuando rechazamos la hipótesis nula de manera errónea, le llamamos \textbf{error tipo I}, cuando no rechazamos la hipótesis nula siendo esta falsa, le llamamos \textbf{error tipo II}.

\begin{figure}[H]
    \center
    \includegraphics[scale=0.2]{notebooks/STATS/img/type_of_errors.png}
    \caption{Types of Errors Diagram}
\end{figure}

\subsubsection{Mean of Normal Distribution - Unknown Variance}

Cuando no conocemos la varianza de la distribución, el estadístico $Z_n$ se puede escribir según 
$$ 
t = \frac{\overline{X} - \mu_0}{s / \sqrt{n}}
$$
Con $s$ la desviación estándar de la muestra $X_1 , \dots, X_n$. En este caso, $t \sim T_{\text{student}}(n-1)$ una distribución t-student con $n-1$ grados de libertad. 

\subsubsection{Proportion Test}

Sea $X_1 \dots X_n \sim \text{Bernoulli}(p)$, definimos el test 

\begin{equation*}
\begin{aligned}
    H_0: p \geq p_0 \\ 
    H_A: p < p_0
\end{aligned}
\end{equation*}

Nuevamente, bajo la hipótesis nula $p = p_0$ por TCL para $n$ grande
$$ 
\overline{X} = \hat{p} \sim \mathcal{N} \left ( p_0 , \frac{p_0(1-p_0)}{n} \right )
$$
Es decir, el estadístico queda definido por $Z = \frac{\hat{p} - p_0}{\frac{\sqrt{p_0(1-p_0)}}{n}}$. 

\subsection{AB Testing}

Un AB Testing es un procedimiento que involucra dividir la población en un grupo de control y un grupo de tratamiento para testear 2 versiones de una única variable. El objetivo es determinar si la estrategia $A$ es más efectiva que una estrategia $B$ para alguna medida de interés.

\subsubsection{Chi - Squared Test}

Consideremos el testing de una variable categórica (ej: click / no click de un post) 

\subsubsection{T - Test}

Consideremos el testing de una variable numérica continua (ej: monto de la compra)  

\subsection{Causal Inference}

La inferencia causal es el proceso de determinar el \textbf{efecto independiente de una variable} en un sistema más complejo. En general, este proceso es necesario cuando buscamos obtener conclusiones de datos pasados y en los que no es posible realizar un \textit{A/B testing}.

Existen 3 desafíos al realizar este proceso: 
\begin{itemize}
    \item \textbf{Cofounders}: Son aquellas variables que tienen un impacto en el outcome y que incluso podrían tener un impacto en otras variables. 
    \item \textbf{Selection Bias}: Selección no representativa del grupo de control y tratamiento.
    \item \textbf{Counterfactuals}: Imputar valores en el grupo de control y tratamiento en base a \textit{Machine Learning} o algoritmos de \textit{Matching}. 
\end{itemize}

\begin{figure}[H]
    \center
    \includegraphics[scale=0.3]{notebooks/STATS/img/causal_inference_diagram.png}
    \caption{Casual Inference - DAG Diagram}
\end{figure}

Para resolver este problema, es necesario tomar algunos supuestos: 
\begin{enumerate}
    \item \textbf{Causal Markov Condition}: La influencia de las variables y el outcome puede ser representado a través de un \textbf{Grafo Acíclico Dirigido (DAG)} en el que se asume la \textbf{condición de Markov}, es decir si $Y \rightarrow S \rightarrow C$, podemos asumir que $C \indep Y | S$
    \item \textbf{SUTVA}: (Stable Unit Treatment Value Assumption) El grupo de control y tratamiento \textbf{no tiene influencia el uno con el otro}. 
    \item \textbf{Ignorability}: Se excluye el ruido proveniente de cualquier otra fuente. 
\end{enumerate}

Consideremos el siguiente ejemplo en el que buscamos determinar si el efecto de un tratamiento tiene un impacto en una variable target. 

\begin{figure}[H]
    \center
    \includegraphics[scale=0.5]{notebooks/STATS/img/causal_inference_age_distribution.png}
    \caption{Casual Inference - Distribution Example}
\end{figure}

Vemos que existe un \textit{selection bias} pues el grupo de tratamiento y control tienen distribuciones de edad distintas. Existen múltiples enfoques para resolver este problema. 

\subsubsection{Matching Imputation}

Es posible utilizar un algoritmo de \textit{Matching} como \textit{NearestNeighbors} para imputar el posible outcome que hubiese tenido un individuo al recibir o no el tratamiento. En nuestro ejemplo, para cada edad de los individuos del grupo de control, buscaríamos al sujeto con la edad más cercana en el grupo de tratamiento e imputaríamos su respuesta al tratamiento y viceversa. 

La efectividad del tratamiento se puede medir a través del promedio de los outcome cuando reciben y cuando no reciben el tratamiento. 

\subsubsection{Meta Learners}

Este enfoque plantea utilizar algoritmos de \textit{Machine Learning} para determinar el efecto del tratamiento en el outcome del experimento. Sea $y_i$ el target, $w$ si recibió el tratamiento y $X_i$ el conjunto de variables del modelo, definimos ITE (\textit{Individual Treatment Effect}) según 
$$
\text{ITE} = \left [ p(y_i = 1 | w_i = 1, X_i) - p(y_i = 1 | w_i = 0, X_i) \right ]
$$

\begin{itemize}
    \item \textbf{S - Model} Este algoritmo es el más simple de todos pues agrega la variable \textit{treatment} como input de un único modelo. El valor de ITE es calculado para cada individuo variando el valor del tratamiento. 
    \item \textbf{T - Model} Este algoritmo entrena 2 clasificadores, uno encargado del grupo de control y otro para el grupo de tratamiento. El valor de ITE es calculado como la resta del output de ambos modelos. 

    Hay que tener en consideración que este modelo requiere una \textbf{calibración} para asegurar que el output de los modelos sean probabilidades.
    \item \textbf{X - Model}: SOON 
\end{itemize}


\begin{figure}[H]
    \center
    \includegraphics[scale=0.5]{notebooks/STATS/img/causal_inference_meta_learners.png}
    \caption{Meta Learners}
\end{figure}

Vemos así que el impacto del tratamiento aislando el efecto de la edad, ocurre según ITE entre los 35 y 45 años. 





